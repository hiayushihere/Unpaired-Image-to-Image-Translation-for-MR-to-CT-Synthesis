# Unpaired-Image-to-Image-Translation-for-MR-to-CT-Synthesis

## üìå Overview
This project explores **unpaired medical image translation** for **MR-to-CT brain image synthesis** using state-of-the-art GAN-based architectures. The study compares **CycleGAN**, **Augmented CycleGAN**, **Contrastive Unpaired Translation (CUT)**, and a **novel Hybrid GAN** that integrates cycle-consistency, contrastive learning, and data augmentation.

The goal is to generate **CT-like images from MR scans without paired data**, reducing the need for dual-modality acquisition in clinical workflows such as **radiotherapy planning**.

---

## üß† Key Contributions
- Comparative analysis of **three unpaired translation frameworks**
- Proposal of a **Hybrid GAN (Augmented CycleGAN + CUT)**
- Extensive evaluation using:
  - **FID, LPIPS**
  - **SSIM, PSNR**
  - **MSE, RMSE**
- **Explainable AI (XAI)** analysis using saliency maps and Grad-CAM
- Experiments conducted on **two unpaired MR‚ÄìCT brain datasets**

---

## üèóÔ∏è Models Implemented
### 1. CycleGAN (Baseline)
- Dual generators (MR ‚Üí CT, CT ‚Üí MR)
- Cycle-consistency and identity losses

### 2. Augmented CycleGAN
- On-the-fly data augmentation (rotations, flips, intensity jitter)
- Latent reconstruction loss
- Improved generalization on small datasets

### 3. CUT (Contrastive Unpaired Translation)
- Single generator‚Äìdiscriminator
- PatchNCE contrastive loss for content preservation
- Reduced computational complexity

### 4. Hybrid GAN (Proposed)
- Combines:
  - Cycle-consistency (CycleGAN)
  - Contrastive PatchNCE loss (CUT)
  - Data augmentation and latent reconstruction loss
- Optimized using **RMSProp**
- Achieves the best balance between realism and anatomical fidelity

---

## üìÇ Datasets Used
Two publicly available **unpaired brain MR‚ÄìCT datasets**:

### Dataset 1: Unpaired MR‚ÄìCT Brain Dataset
- 179 axial slices  
- 90 MR (T1-weighted), 89 CT  
- Resolution: 256 √ó 256  

### Dataset 2: CT-to-MRI CGAN Dataset
- 402 unpaired slices (201 MR, 201 CT)
- Multi-planar views (axial, coronal, sagittal)
- Diverse scanners and slice thicknesses

### Preprocessing
- Resize/crop to 256 √ó 256  
- Intensity normalization to **[-1, 1]**  
- Grayscale ‚Üí pseudo-RGB (3 channels)  
- 80/20 train‚Äìtest split  
- Data augmentation for selected models  

---

## ‚öôÔ∏è Training Configuration
- **Framework**: PyTorch  
- **Input Size**: 256 √ó 256 √ó 3  
- **Batch Size**: 1  
- **Epochs**: 100  
- **Optimizers**:
  - Adam (CycleGAN, Augmented CycleGAN, CUT)
  - RMSProp (Hybrid GAN)
- **Hardware**: NVIDIA Tesla T4 (Kaggle)

---

## üìä Evaluation Metrics
| Category        | Metrics              |
|-----------------|---------------------|
| Distribution    | FID                 |
| Perceptual      | LPIPS               |
| Structural      | SSIM                |
| Pixel-level     | MSE, RMSE           |
| Reconstruction  | PSNR                |

---

## üîç Explainable AI (XAI)
- **Grad-CAM** applied to generators and discriminators
- Saliency maps highlight:
  - Ventricles
  - Cortical folds
  - Subcortical regions
- Hybrid model shows **most localized and clinically relevant attention**

---

## üèÜ Results Summary
- **Hybrid GAN outperforms all baselines**
- Lowest FID and RMSE
- Improved SSIM and PSNR
- Best trade-off between:
  - Anatomical structure
  - Perceptual realism
  - Interpretability

---

## üöÄ Applications
- Radiotherapy treatment planning
- CT-free dose calculation
- Cross-modality medical imaging
- Low-resource clinical environments
